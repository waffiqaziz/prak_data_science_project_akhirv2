---
title: "Project3"
author: "123190070 - 123190064"
date: "4/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) # auto set directory

# library(readr)
library(tm)
library(corpus)
library(tidymodels)
library(dplyr) # Data wrangling & manipulation
library(tidytext) # For unnest_tokens
library(stringr) # For managing text
library(ggplot2) # For data visualizations & graphs

# wordcloud
library(wordcloud)
library(RColorBrewer)

```


```{r}
df <- read.csv("Coronavirus_Tweets.csv")
df$TweetAt <- sub("-", "/", df$TweetAt)
df$TweetAt <- sub("-", "/", df$TweetAt)
df$TweetAt <- as.Date(df$TweetAt , format = "%d/%m/%y")
# df = na.omit(df)
```


melihat jumlah tiap sentiment
```{r}
df %>%
  group_by(Sentiment) %>% 
  tally() %>% 
  ggplot(aes(x=Sentiment, y=n, fill = Sentiment)) +
  theme(axis.text.x = element_text(angle = 45)) +
  geom_col() +
  geom_text(
    aes(label = n), 
    colour = "black", 
    fontface = "bold",
    position=position_dodge(width=0.9), 
    vjust=-0.25)
  # geom_text(
  #   # label rata-rata dibulatkan tiga angka terakhir
  #   aes(x = Sentiment, y = n, label = n), 
  #   hjust = 1, size = 4,
  #   position = position_dodge(width = 1),
  #   inherit.aes = TRUE
  # ) 
```

sentimen yang bernilai extremely positive
```{r}
df %>%
  filter(Sentiment == "Extremely Positive")
```
```{r}

df %>%
  group_by(TweetAt) %>% 
  tally() %>%
  ggplot(aes(x=TweetAt, y=n)) +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_x_date(breaks = df$TweetAt) + 
  geom_bar(stat = "identity") 
```


show most world on location
```{r}
text <- c(df$Location)
text <- paste(text, collapse = " ")
text <- str_replace_all(text, pattern = '\"', replacement = "") # Remove slashes
text <- str_replace_all(text, pattern = '\n', replacement = "") # Remove \n
text <- str_replace_all(text, pattern = '\u0092', replacement = "'") #Replace with quote
text <- str_replace_all(text, pattern = '\u0091', replacement = "'") #Replace with quote

text_df <- data_frame(Text = text) # tibble aka neater data frame
text_words <- text_df %>% 
  unnest_tokens(output = word, input = Text) 

# data(stop_words) # Stop words.
text_words  <- text_words  %>%
  anti_join(stop_words) # Remove stop words in peter_words


# Word Counts:
text_wordcounts <- text_words  %>% count(word, sort = TRUE)

head(text_wordcounts)
```
```{r}
df$Tweets <- sapply(strsplit(as.character(df$OriginalTweet),split=' '),function(s) paste(s[!grepl('^@',s)],collapse=' ')) 
df$Tweets <- sapply(strsplit(as.character(df$Tweets),split=' '),function(s) paste(s[!grepl('^https:',s)],collapse=' '))
```


Menghilangkan kata yang mengandung https dan @
```{r}
df$Tweets <- sapply(strsplit(as.character(df$OriginalTweet),split=' '),function(s) paste(s[!grepl('^@',s)],collapse=' '))

df$Tweets <- gsub("(?:\\s+|^)\\S*(?<!\\w)(?:@?|<filter>)(?!\\w)\\S*", "", df$Tweets, perl=TRUE)
# df$Tweets <- gsub("(?:\\s+|^)\\S*(?<!\\w)(?:https?|<filter>)(?!\\w)\\S*", "", df$Tweets, perl=TRUE)

# df$Tweets <- gsub("(?:\\s+|^)\\S*(?<!\\w)(?:amp?|<filter>)(?!\\w)\\S*", "", df$Tweets, perl=TRUE)
# df$Tweets <- gsub("(?:\\s+|^)\\S*(?<!\\w)(?:[\r\n]?|<filter>)(?!\\w)\\S*", "", df$Tweets, perl=TRUE)
# df$Tweets <- gsub("(?:\\s+|^)\\S*(?<!\\w)(?:[[:punct:]]?|<filter>)(?!\\w)\\S*", "", df$Tweets, perl=TRUE)
```

world cloud
```{r}
docs <- Corpus(VectorSource(df$Tweets))

docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>% #Remove commas etc.
  tm_map(stripWhitespace) %>%
  tm_map(stemDocument)
docs <- tm_map(docs, content_transformer(tolower))

# menghilangkan konjungsi
docs <- tm_map(docs, removeWords, stopwords("english"))
```
```{r}
# set.seed(1234) # for reproducibility 
wordcloud(docs
          , max.words=500    # Set top n words
          , random.order=FALSE # Words in decreasing freq
          , rot.per=0.35       # % of vertical words
          , use.r.layout=FALSE # Use C++ collision detection
          , colors=brewer.pal(8, "Dark2"))
```



```{r}
words <- df$Tweets

words <- data_frame(Text = words)
# head(words, n = 20)
words <- words %>%
   # tm_map(removePunctuation) %>%
  unnest_tokens(output = word, input = Text)%>%
  anti_join(stop_words) %>% # Remove stop words in peter_words
  count(word, sort = TRUE)

words = na.omit(words) #hapus baris yang kososng


# words <- gsub("[0-9]+", "", words$word) 
```

Plot top words
```{r}
words %>% 
  filter(n > 2000) %>% 
  mutate(word = reorder(word, n)) %>% 
    ggplot(aes(word, n)) + 
    geom_col() +
    coord_flip() +
    labs(x = "Word \n", y = "\n Count ", title = "Frequent Words\n") +
    geom_text(aes(label = n), hjust = 1.2, colour = "white", fontface = "bold") +
    theme(plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(face="bold", colour="darkblue", size = 12),
        axis.title.y = element_text(face="bold", colour="darkblue", size = 12))
```







